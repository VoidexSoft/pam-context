---
phase: 07-ingestion-pipeline-extension-diff-engine
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - src/pam/ingestion/pipeline.py
  - src/pam/ingestion/task_manager.py
  - src/pam/api/routes/ingest.py
  - src/pam/api/deps.py
  - web/src/api/client.ts
  - web/src/pages/AdminDashboard.tsx
autonomous: true
requirements:
  - EXTRACT-04
  - EXTRACT-05
  - DIFF-03

must_haves:
  truths:
    - "Ingesting a document triggers graph extraction after PG+ES commit, wrapped in try/except"
    - "Graph failure sets graph_synced=False but document is still committed to PG and ES"
    - "Graph success sets graph_synced=True and logs diff summary to SyncLog.details"
    - "Partial graph failure triggers rollback of all episodes added in this ingestion run"
    - "?skip_graph=true query param skips graph extraction during ingestion"
    - "POST /ingest/sync-graph retries graph extraction for unsynced documents"
    - "Sync endpoint respects ?limit=N and max retry count (3) before marking permanently failed"
    - "Sync response includes per-document results with synced/failed lists and remaining count"
    - "Re-ingestion only sends changed chunks through Graphiti (diff engine integration)"
    - "Diff summary is both returned in IngestionResult and persisted in SyncLog.details"
    - "Admin dashboard has a Sync Graph button that calls POST /ingest/sync-graph with loading state"
  artifacts:
    - path: "src/pam/ingestion/pipeline.py"
      provides: "Extended pipeline with graph extraction step after ES write"
      contains: "extract_graph_for_document"
    - path: "src/pam/ingestion/task_manager.py"
      provides: "Graph service passed through to pipeline"
      contains: "graph_service"
    - path: "src/pam/api/routes/ingest.py"
      provides: "POST /ingest/sync-graph endpoint and skip_graph param"
      contains: "sync-graph"
    - path: "src/pam/api/deps.py"
      provides: "Unchanged but referenced for get_graph_service dependency"
    - path: "web/src/pages/AdminDashboard.tsx"
      provides: "Sync Graph button in admin dashboard"
      contains: "sync-graph"
    - path: "web/src/api/client.ts"
      provides: "syncGraph() API client function"
      contains: "syncGraph"
  key_links:
    - from: "src/pam/ingestion/pipeline.py"
      to: "src/pam/graph/extraction.py"
      via: "extract_graph_for_document() call after ES write"
      pattern: "extract_graph_for_document"
    - from: "src/pam/ingestion/pipeline.py"
      to: "src/pam/graph/extraction.py"
      via: "rollback_graph_for_document() call on exception"
      pattern: "rollback_graph_for_document"
    - from: "src/pam/ingestion/pipeline.py"
      to: "src/pam/ingestion/stores/postgres_store.py"
      via: "set_graph_synced() and get_segments_for_document() calls"
      pattern: "set_graph_synced"
    - from: "src/pam/api/routes/ingest.py"
      to: "src/pam/ingestion/stores/postgres_store.py"
      via: "get_unsynced_documents() for sync-graph endpoint"
      pattern: "get_unsynced_documents"
    - from: "src/pam/ingestion/task_manager.py"
      to: "src/pam/ingestion/pipeline.py"
      via: "graph_service parameter passed to IngestionPipeline"
      pattern: "graph_service"
---

<objective>
Wire graph extraction into the ingestion pipeline, add the sync recovery endpoint, and extend the ingest API with skip_graph support.

Purpose: This plan connects the extraction orchestrator and diff engine (from Plan 01) into the live ingestion flow. Documents ingested through the pipeline will now produce graph data in Neo4j. Failed graph extractions are tracked and retryable via the sync endpoint. The pipeline remains fault-tolerant -- graph failures never corrupt PG/ES data.

Output: Modified pipeline.py with graph extraction step, task_manager.py passing graph_service, ingest route with POST /ingest/sync-graph and ?skip_graph support.
</objective>

<execution_context>
@/Users/datnguyen/.claude/get-shit-done/workflows/execute-plan.md
@/Users/datnguyen/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-ingestion-pipeline-extension-diff-engine/07-RESEARCH.md
@.planning/phases/07-ingestion-pipeline-extension-diff-engine/07-01-SUMMARY.md
@src/pam/ingestion/pipeline.py
@src/pam/ingestion/task_manager.py
@src/pam/api/routes/ingest.py
@src/pam/api/deps.py
@src/pam/graph/extraction.py
@src/pam/ingestion/diff_engine.py
@src/pam/ingestion/stores/postgres_store.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire graph extraction into pipeline + task manager</name>
  <files>
    src/pam/ingestion/pipeline.py
    src/pam/ingestion/task_manager.py
  </files>
  <action>
    **pipeline.py modifications:**

    1. Add new imports at top of file:
       ```python
       from pam.graph.extraction import ExtractionResult, extract_graph_for_document, rollback_graph_for_document
       ```
       Use TYPE_CHECKING for `GraphitiService` to avoid heavy import:
       ```python
       from typing import TYPE_CHECKING
       if TYPE_CHECKING:
           from pam.graph.service import GraphitiService
       ```

    2. Add `graph_service` and `skip_graph` fields to `IngestionPipeline` dataclass:
       ```python
       graph_service: GraphitiService | None = None
       skip_graph: bool = False
       ```

    3. Extend `IngestionResult` dataclass with graph fields:
       ```python
       graph_synced: bool = False
       graph_entities_extracted: int = 0
       diff_summary: dict | None = None
       ```

    4. After step 10 (ES write) and before the final `logger.info("pipeline_complete"...)`, add step 11 -- graph extraction:
       ```python
       # 11. Graph extraction (non-blocking -- failure never rolls back PG/ES)
       graph_synced = False
       diff_summary = None
       graph_entities_count = 0
       if self.graph_service and not self.skip_graph:
           try:
               # Get old segments for diff (re-ingestion case)
               old_segments = None
               if existing_doc:
                   old_segments_raw = await pg_store.get_segments_for_document(existing_doc.id)
                   old_segments = old_segments_raw if old_segments_raw else None

               extraction_result = await extract_graph_for_document(
                   graph_service=self.graph_service,
                   doc_id=doc_id,
                   segments=segments,
                   document_title=raw_doc.title,
                   reference_time=getattr(raw_doc, 'modified_at', None) or datetime.now(UTC),
                   source_id=source_id,
                   old_segments=old_segments,
               )
               graph_synced = True
               diff_summary = extraction_result.diff_summary
               graph_entities_count = len(extraction_result.entities_extracted)
               await pg_store.set_graph_synced(doc_id, True)

               # Update segment metadata with episode UUIDs (need to save back to PG)
               for seg_ks, seg_db in zip(segments, [...segments from DB...]):
                   if seg_ks.metadata.get("graph_episode_uuid"):
                       # Update segment metadata in DB
                       pass
               # Actually: the segments were already saved. We need to update their metadata_
               # after extraction. Use a bulk update or flush.
               # Simpler approach: update via session
               for seg in segments:
                   if seg.metadata.get("graph_episode_uuid"):
                       from sqlalchemy import update as sa_update
                       await self.session.execute(
                           sa_update(Segment)
                           .where(Segment.id == seg.id)
                           .values(metadata_=seg.metadata)
                       )
               await self.session.commit()

               # Log graph sync event with diff summary
               await pg_store.log_sync(doc_id, "graph_synced", graph_entities_count, details=diff_summary or {})

               logger.info("pipeline_graph_extraction_complete",
                   source_id=source_id, entities=graph_entities_count,
                   episodes_added=extraction_result.episodes_added)
           except Exception as graph_err:
               logger.error("pipeline_graph_extraction_failed",
                   source_id=source_id, doc_id=str(doc_id), error=str(graph_err))
               await pg_store.set_graph_synced(doc_id, False)
               # Rollback any partial graph writes for this document
               try:
                   rolled_back = await rollback_graph_for_document(self.graph_service, segments)
                   logger.info("pipeline_graph_rollback", source_id=source_id, episodes_rolled_back=rolled_back)
               except Exception:
                   logger.error("pipeline_graph_rollback_failed", source_id=source_id)
       ```

       IMPORTANT REFINEMENT: The above is pseudo-code showing the structure. In the actual implementation:
       - Import `datetime` and `UTC` from the datetime module (add `from datetime import UTC, datetime` to imports)
       - Import `Segment` from models (add to existing import)
       - The `old_segments` retrieval must happen BEFORE `save_segments()` deletes the old segments. Move the old segment retrieval to BEFORE step 7 (PG write). Store as `old_segments_for_diff` variable.
       - After extraction, update segment metadata by executing SQL UPDATE for each segment that has a `graph_episode_uuid` in its metadata, then commit.
       - The `pg_store.log_sync()` call for graph sync is separate from the existing sync log for create/update. Use action="graph_synced".
       - Add a new session commit after updating segment metadata (the PG data was already committed in step 9).

    5. Update the return statement to include graph fields:
       ```python
       return IngestionResult(
           source_id=source_id, title=raw_doc.title, segments_created=count,
           graph_synced=graph_synced, graph_entities_extracted=graph_entities_count,
           diff_summary=diff_summary,
       )
       ```

    **task_manager.py modifications:**

    1. Add `graph_service` parameter to `spawn_ingestion_task()`:
       ```python
       def spawn_ingestion_task(
           task_id: uuid.UUID,
           folder_path: str,
           es_client: AsyncElasticsearch,
           embedder: BaseEmbedder,
           session_factory: async_sessionmaker,
           cache_service: CacheService | None = None,
           graph_service: GraphitiService | None = None,
           skip_graph: bool = False,
       ) -> None:
       ```
       Use TYPE_CHECKING for GraphitiService import. Pass it through to `run_ingestion_background()`.

    2. Add `graph_service` and `skip_graph` parameters to `run_ingestion_background()`:
       Pass them through to the `IngestionPipeline()` constructor:
       ```python
       pipeline = IngestionPipeline(
           connector=connector,
           parser=parser,
           embedder=embedder,
           es_store=es_store,
           session=pipeline_session,
           source_type="markdown",
           progress_callback=on_progress,
           graph_service=graph_service,
           skip_graph=skip_graph,
       )
       ```

    3. Update the progress callback `on_progress()` to include graph fields in the result entry:
       ```python
       result_entry = [{
           "source_id": result.source_id,
           "title": result.title,
           "segments_created": result.segments_created,
           "skipped": result.skipped,
           "error": result.error,
           "graph_synced": result.graph_synced,
           "graph_entities_extracted": result.graph_entities_extracted,
       }]
       ```
  </action>
  <verify>
    - Run `ruff check src/pam/ingestion/pipeline.py src/pam/ingestion/task_manager.py` -- no lint errors
    - Run `python -c "from pam.ingestion.pipeline import IngestionPipeline, IngestionResult; print(hasattr(IngestionResult, 'graph_synced'))"` -- prints True
    - Run `python -c "from pam.ingestion.task_manager import spawn_ingestion_task; import inspect; sig = inspect.signature(spawn_ingestion_task); print('graph_service' in sig.parameters)"` -- prints True
    - Verify no circular imports: `python -c "from pam.ingestion.pipeline import IngestionPipeline; print('OK')"`
  </verify>
  <done>
    Pipeline calls extract_graph_for_document() after PG+ES commit, wrapped in try/except. Graph failure sets graph_synced=False without affecting PG/ES data. Success stores episode UUIDs in segment metadata and logs diff summary. task_manager passes graph_service and skip_graph through to the pipeline. Re-ingestion retrieves old segments before deletion for chunk-level diff comparison.
  </done>
</task>

<task type="auto">
  <name>Task 2: Sync recovery endpoint + skip_graph param + Sync Graph button</name>
  <files>
    src/pam/api/routes/ingest.py
    web/src/api/client.ts
    web/src/pages/AdminDashboard.tsx
  </files>
  <action>
    **Add POST /ingest/sync-graph endpoint:**

    Create a new endpoint in ingest.py:
    ```python
    MAX_GRAPH_SYNC_RETRIES = 3  # Per user discretion: exact count is Claude's choice

    @router.post("/ingest/sync-graph")
    async def sync_graph(
        request: Request,
        limit: int | None = Query(default=None, description="Max documents to retry"),
        db: AsyncSession = Depends(get_db),
        _admin: User | None = Depends(require_admin),
    ):
    ```

    Implementation:
    1. Get graph_service from `request.app.state.graph_service`. If None, return HTTP 503 with detail "Graph service not available".
    2. Create a `PostgresStore(db)` instance.
    3. Call `pg_store.get_unsynced_documents(max_retries=MAX_GRAPH_SYNC_RETRIES, limit=limit)`.
    4. For each unsynced document:
       - Get segments via `pg_store.get_segments_for_document(doc.id)`
       - Build KnowledgeSegment-like objects from Segment ORM rows (or pass Segment objects directly -- the extraction function can work with segments that have .content, .content_hash, .id, .position, .metadata_ attributes)
       - Actually, `extract_graph_for_document()` expects `list[KnowledgeSegment]`. We need to convert Segment ORM objects. Create a simple helper that builds KnowledgeSegment from Segment: `KnowledgeSegment(content=seg.content, content_hash=seg.content_hash, segment_type=seg.segment_type, section_path=seg.section_path, position=seg.position, metadata=seg.metadata_ or {})`
       - Note: For sync-graph, there are no "old_segments" -- we're doing first-time extraction for documents that previously failed, so pass `old_segments=None`
       - Call `extract_graph_for_document(graph_service, doc.id, segments_ks, doc.title, doc.last_synced_at or datetime.now(UTC), doc.source_id)`
       - On success: call `pg_store.set_graph_synced(doc.id, True)`, add to `synced` list with `{doc_id, status: "synced", entities_added: len(result.entities_extracted)}`
       - Log diff to SyncLog: `await pg_store.log_sync(doc.id, "graph_synced", len(result.entities_extracted), details=result.diff_summary)`
       - On failure: call `pg_store.set_graph_synced(doc.id, False, increment_retries=True)`, rollback episodes, add to `failed` list with `{doc_id, error: str(e)}`
       - Commit after each document to avoid losing progress
    5. Count remaining unsynced documents (another query with same filters).
    6. Return JSON response: `{"synced": synced_list, "failed": failed_list, "remaining": remaining_count}`

    **Add skip_graph query param to ingest_folder endpoint:**
    Add `skip_graph: bool = Query(default=False, description="Skip graph extraction")` parameter to `ingest_folder()`.
    Pass it through to `spawn_ingestion_task()`:
    ```python
    spawn_ingestion_task(
        task.id, body.path, es_client, embedder,
        session_factory=request.app.state.session_factory,
        cache_service=request.app.state.cache_service,
        graph_service=request.app.state.graph_service,
        skip_graph=skip_graph,
    )
    ```

    **Add necessary imports:**
    - `from pam.graph.extraction import extract_graph_for_document, rollback_graph_for_document`
    - `from pam.ingestion.stores.postgres_store import PostgresStore`
    - `from pam.common.models import KnowledgeSegment, Segment`
    - `from datetime import UTC, datetime`

    Note: Use `getattr(request.app.state, 'graph_service', None)` pattern for safe access to graph_service since it may not be set if Neo4j is unavailable.

    **Frontend: API client function (web/src/api/client.ts):**
    Add a `syncGraph` function and response type:
    ```typescript
    export interface SyncGraphResult {
      synced: Array<{ doc_id: string; status: string; entities_added: number }>;
      failed: Array<{ doc_id: string; error: string }>;
      remaining: number;
    }

    export async function syncGraph(limit?: number): Promise<SyncGraphResult> {
      const params = limit ? `?limit=${limit}` : "";
      const res = await fetch(`${API_BASE}/ingest/sync-graph${params}`, { method: "POST" });
      if (!res.ok) throw new Error(`Sync graph failed: ${res.status}`);
      return res.json();
    }
    ```

    **Frontend: Admin Dashboard Sync Graph button (web/src/pages/AdminDashboard.tsx):**
    Read the existing AdminDashboard.tsx to understand its structure and styling patterns. Add a "Sync Graph" section/card with:
    - A button labeled "Sync Graph" with a graph/refresh icon
    - Loading state (spinner or "Syncing..." text) while the request is in flight
    - On success: show count of synced/failed documents and remaining
    - On error: show error message
    - Button disabled while syncing
    - Use the same Tailwind card/button styling patterns as existing dashboard components
    - Per user discretion: keep the loading/progress UI simple -- a spinning indicator and result summary is sufficient
  </action>
  <verify>
    - Run `ruff check src/pam/api/routes/ingest.py` -- no lint errors
    - Run `python -c "from pam.api.routes.ingest import router; routes = [r.path for r in router.routes]; print('/ingest/sync-graph' in routes)"` -- prints True
    - Verify skip_graph parameter exists: `python -c "from pam.api.routes.ingest import ingest_folder; import inspect; sig = inspect.signature(ingest_folder); print('skip_graph' in sig.parameters)"` -- prints True
  </verify>
  <done>
    POST /ingest/sync-graph endpoint retries graph extraction for all documents with graph_synced=False, respects limit and max retry count (3), returns per-document results with synced/failed lists and remaining count. The ingest_folder endpoint accepts ?skip_graph=true to opt out of graph extraction. graph_service is passed from app.state through the task manager to the pipeline. Admin dashboard has a "Sync Graph" button with loading state that calls the endpoint and displays results.
  </done>
</task>

</tasks>

<verification>
- Pipeline ingestion calls extract_graph_for_document() after PG+ES commit
- Graph exceptions are caught -- PG/ES data remains intact on graph failure
- graph_synced flag is set to True on success, False on failure
- Partial failures trigger rollback_graph_for_document() to clean up episodes
- ?skip_graph=true skips graph extraction entirely
- POST /ingest/sync-graph queries unsynced docs, retries extraction, updates flags
- Sync endpoint respects ?limit=N and MAX_GRAPH_SYNC_RETRIES=3
- Diff summary persisted in SyncLog.details as structured JSON
- graph_service flows from app.state -> spawn_ingestion_task -> IngestionPipeline
- All files pass ruff check
</verification>

<success_criteria>
- Document ingestion produces graph data when graph_service is available
- Graph failure never corrupts PG/ES data
- Re-ingestion uses diff engine (only changed chunks go through Graphiti)
- Sync recovery endpoint works with limit and retry tracking
- Skip_graph parameter available on ingest endpoint
- All modules are importable and lint-clean
</success_criteria>

<output>
After completion, create `.planning/phases/07-ingestion-pipeline-extension-diff-engine/07-02-SUMMARY.md`
</output>
